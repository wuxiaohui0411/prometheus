#my global config
global:
  scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout:300s  # is set to the global default (10s).

# Alertmanager configuration
alerting:
  alertmanagers:
  - static_configs:
    - targets: ['localhost:9093']

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  # - "first_rules.yml"
    - "rules/*.yml"
# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.


scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: 'prometheus'

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.
    static_configs:
    - targets: ['localhost:9090']

  - job_name: 'linux'
    scrape_timeout: 15s
    scrape_interval: 15s
    file_sd_configs:
    - refresh_interval: 60s
      files:
      - "/usr/local/prometheus/JobGroup/linux_node.yml"


    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

  - job_name: 'windows'
    scrape_timeout: 15s
    scrape_interval: 15s
    file_sd_configs:
    - refresh_interval: 60s
      files:
      - "/usr/local/prometheus/JobGroup/windows_node.yml"


  - job_name: 'oracle'
    scrape_timeout: 15s
    scrape_interval: 15s
    file_sd_configs:
    - refresh_interval: 60s
      files:
      - "/usr/local/prometheus/JobGroup/oracle_node.yml"

  - job_name: 'tomcat'
    scrape_timeout: 15s
    scrape_interval: 15s
    file_sd_configs:
    - refresh_interval: 60s
      files:
      - "/usr/local/prometheus/JobGroup/tomcat_node.yml"

  - job_name: 'blackbox-tcp'
    scrape_timeout: 15s
    scrape_interval: 15s
    metrics_path: /probe
    params:
      module: [tcp_connect]
    file_sd_configs:
    - refresh_interval: 60s
      files:
      - "/usr/local/prometheus/JobGroup/blackbox_tcp.yml"
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 10.32.224.84:9115

  - job_name: 'cert'
    scrape_timeout: 15s
    scrape_interval: 15s
    metrics_path: /probe
    params:
      module: [http_2xx]
    file_sd_configs:
    - refresh_interval: 60s
      files:
      - "/usr/local/prometheus/JobGroup/cert.yml"
    relabel_configs:
    - source_labels: [__address__]
      target_label: __param_target
    - source_labels: [__param_target]
      target_label: instance
    - target_label: __address__
      replacement: 10.32.224.84:9115 #安装Exporter的服务器地址以及端口

  - job_name: 'bpm_blackbox-https'
    scrape_timeout: 15s
    scrape_interval: 15s
    metrics_path: /probe
    params:
      module: [bpm_http_2xx]
    file_sd_configs:
    - refresh_interval: 60s
      files:
      - "/usr/local/prometheus/JobGroup/bpm_URL_body.yml"
    relabel_configs:
    - source_labels: [__address__]
      target_label: __param_target
    - source_labels: [__param_target]
      target_label: instance
    - target_label: __address__
      replacement: 10.32.224.84:9115 #安装Exporter的服务器地址以及端口

  - job_name: 'mssql'
    static_configs:
    - targets: ['10.32.136.43:9399']


  - job_name: 'snmp'
    # 采集超时：10s
    scrape_interval: 10s
    static_configs:
    - targets: [10.32.224.71]  #交换机ip
    - targets: [10.33.32.38]  #乐康金岳
    metrics_path: /snmp
#    params:
#      module: [huawei_mib]  #修改成2.4步自己设置的mib名称
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 10.32.224.84:9116  # 安装snmp_exporter主机的ip和端口号